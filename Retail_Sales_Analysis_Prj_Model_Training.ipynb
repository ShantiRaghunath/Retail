{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa288e2-5f9e-428f-98c8-ebd980c7c6a5",
   "metadata": {},
   "source": [
    "# Package Installation for Snowflake Connection and Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b943968-da70-42a3-8b10-18ac34471919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[complete] in /opt/conda/lib/python3.9/site-packages (2024.8.0)\n",
      "Requirement already satisfied: snowflake in /opt/conda/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: snowflake-connector-python in /opt/conda/lib/python3.9/site-packages (3.12.4)\n",
      "Requirement already satisfied: snowflake-snowpark-python in /opt/conda/lib/python3.9/site-packages (1.26.0)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.6.0)\n",
      "Requirement already satisfied: fosforml in /opt/conda/lib/python3.9/site-packages (1.1.9)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.9/site-packages (5.24.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /opt/conda/lib/python3.9/site-packages (from dask[complete]) (2023.12.2)\n",
      "Requirement already satisfied: partd>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from dask[complete]) (1.4.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from dask[complete]) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0; python_version < \"3.12\" in /opt/conda/lib/python3.9/site-packages (from dask[complete]) (8.2.0)\n",
      "Requirement already satisfied: click>=8.1 in /opt/conda/lib/python3.9/site-packages (from dask[complete]) (8.1.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from dask[complete]) (24.1)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from dask[complete]) (2.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.9/site-packages (from dask[complete]) (6.0.1)\n",
      "Requirement already satisfied: pyarrow>=7.0; extra == \"complete\" in /opt/conda/lib/python3.9/site-packages (from dask[complete]) (18.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix; extra == \"complete\" in /opt/conda/lib/python3.9/site-packages (from dask[complete]) (0.6)\n",
      "Requirement already satisfied: lz4>=4.3.2; extra == \"complete\" in /opt/conda/lib/python3.9/site-packages (from dask[complete]) (4.3.3)\n",
      "Requirement already satisfied: snowflake-core==1.0.2 in /opt/conda/lib/python3.9/site-packages (from snowflake) (1.0.2)\n",
      "Requirement already satisfied: snowflake-legacy in /opt/conda/lib/python3.9/site-packages (from snowflake) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (4.12.2)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (4.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (3.7)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.21.1; python_version < \"3.10\" in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (2024.7.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (3.3.2)\n",
      "Requirement already satisfied: tomlkit in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (0.13.2)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (3.16.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (2024.1)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (42.0.5)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (2.32.3)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=22.0.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (24.0.0)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (1.16.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (2.10.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from snowflake-snowpark-python) (0.37.1)\n",
      "Requirement already satisfied: tzlocal in /opt/conda/lib/python3.9/site-packages (from snowflake-snowpark-python) (5.2)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.9/site-packages (from snowflake-snowpark-python) (2.9.0.post0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /opt/conda/lib/python3.9/site-packages (from snowflake-snowpark-python) (5.29.2)\n",
      "Requirement already satisfied: setuptools>=40.6.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-snowpark-python) (65.6.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in /opt/conda/lib/python3.9/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: snowflake-ml-python==1.5.0; python_version <= \"3.9\" in /opt/conda/lib/python3.9/site-packages (from fosforml) (1.5.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: locket in /opt/conda/lib/python3.9/site-packages (from partd>=1.4.0->dask[complete]) (1.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.13.0; python_version < \"3.12\"->dask[complete]) (3.19.2)\n",
      "Requirement already satisfied: atpublic>=4 in /opt/conda/lib/python3.9/site-packages (from snowflake-core==1.0.2->snowflake) (5.0)\n",
      "Requirement already satisfied: pydantic>=2 in /opt/conda/lib/python3.9/site-packages (from snowflake-core==1.0.2->snowflake) (2.10.4)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil->snowflake-snowpark-python) (1.16.0)\n",
      "Requirement already satisfied: absl-py<2,>=0.15 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.4.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (0.5.3)\n",
      "Requirement already satisfied: s3fs<2024,>=2022.11 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2023.12.2)\n",
      "Requirement already satisfied: catboost<1.3,>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.2.7)\n",
      "Requirement already satisfied: cachetools<6,>=3.1.1 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (5.5.0)\n",
      "Requirement already satisfied: retrying<2,>=1.3.3 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.3.4)\n",
      "Requirement already satisfied: pytimeparse<2,>=1.1.8 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.1.8)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.7.1)\n",
      "Requirement already satisfied: xgboost<2,>=1.7.3 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.7.6)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.9/site-packages (from pydantic>=2->snowflake-core==1.0.2->snowflake) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from pydantic>=2->snowflake-core==1.0.2->snowflake) (0.7.0)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /opt/conda/lib/python3.9/site-packages (from s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.16.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.9/site-packages (from s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.11.11)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.9/site-packages (from catboost<1.3,>=1.2.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (0.20.3)\n",
      "Requirement already satisfied: exceptiongroup; python_version < \"3.11\" in /opt/conda/lib/python3.9/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.3.1)\n",
      "Requirement already satisfied: botocore<1.35.82,>=1.35.74 in /opt/conda/lib/python3.9/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.35.81)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/lib/python3.9/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.17.0)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /opt/conda/lib/python3.9/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (0.12.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (23.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0; python_version < \"3.11\" in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (5.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (0.2.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.18.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from botocore<1.35.82,>=1.35.74->aiobotocore<3.0.0,>=2.5.4->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install  dask[complete]  snowflake  snowflake-connector-python snowflake-snowpark-python snowflake-snowpark-python[pandas] seaborn matplotlib numpy pandas scikit-learn  fosforml plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273cb1f1-515b-4aaf-a866-271c35f9d532",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85fea648-ed49-4a20-8881-f30c51a95a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing general libraries\n",
    "import pandas as pd  # For data manipulation\n",
    "import numpy as np  # For numerical operations\n",
    "import seaborn as sns  # For data visualization\n",
    "from datetime import datetime  # For date and time manipulation\n",
    "import matplotlib.pyplot as plt  # For plotting graphs\n",
    "\n",
    "# Importing Snowflake session management\n",
    "from snowflake.snowpark.session import Session  # For Snowflake integration\n",
    "\n",
    "# Importing advanced plotting libraries\n",
    "from plotly.subplots import make_subplots  # For creating subplots in Plotly\n",
    "import plotly.graph_objects as go  # For creating interactive visualizations with Plotly\n",
    "import plotly.express as px  # For simplified plotting using Plotly\n",
    "\n",
    "# Setting Pandas display option to show more columns in the output\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# Importing libraries for machine learning and feature selection\n",
    "from sklearn.ensemble import RandomForestClassifier  # For Random Forest model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, precision_recall_curve, auc  # For model evaluation metrics\n",
    "from sklearn.feature_selection import SelectKBest, f_classif  # For feature selection\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder  # For encoding categorical data and scaling\n",
    "from sklearn.impute import SimpleImputer  # For handling missing values\n",
    "from sklearn.compose import ColumnTransformer  # For applying different preprocessing steps to different columns\n",
    "from sklearn.pipeline import Pipeline  # For creating machine learning pipelines\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV  # For splitting data and performing grid search for hyperparameter tuning\n",
    "\n",
    "# Importing additional libraries for visualization and matplotlib handling\n",
    "import matplotlib.pyplot as plt  # For plotting static visualizations\n",
    "\n",
    "# Setting up environment for plotting using Seaborn and Matplotlib\n",
    "sns.set(style=\"whitegrid\")  # Setting the style for Seaborn plots\n",
    "import pyarrow as pa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bee066-c521-4a3a-80b2-0aac915578f2",
   "metadata": {},
   "source": [
    "# This section connects to Snowflake using fosforml's Snowflake session manager, retrieves data from a specified Snowflake table, and loads the data into a Pandas DataFrame for further processing and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eca5766-1741-4495-b7d1-2814de5f21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing the get_session function from fosforml's Snowflake session manager\n",
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "\n",
    "# Establishing a Snowflake session for executing queries and performing operations\n",
    "my_session = get_session()\n",
    "\n",
    "# Define the name of the Snowflake table to query\n",
    "table_name = 'ORDER_DATA_TRAINING'\n",
    "\n",
    "# Execute a SQL query to select all records from the specified table in Snowflake\n",
    "df_sample = my_session.sql(\"select * from {}\".format(table_name)).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9827dc1-33fd-4079-a763-56fe392010b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIVISION_CODE                              object\n",
       "DIVISION_NAME                              object\n",
       "BRAND_CODE                                 object\n",
       "BRAND_NAME                                 object\n",
       "CLASS_CODE                                 object\n",
       "CLASS_NAME                                 object\n",
       "SELLING_CHANNEL                            object\n",
       "CHAIN                                      object\n",
       "WEB_ORDER_NUMBER                           object\n",
       "OMS_ORDER_NUMBER                           object\n",
       "OMS_LINE_ITEM_ID                           object\n",
       "OMS_TICKET_ID                              object\n",
       "SKU_ID                                     object\n",
       "QUANTITY                                     int8\n",
       "UNIT_PRICE                                float64\n",
       "CURRENT_STATUS                             object\n",
       "CURRENT_STATUS_DESCRIPTION                 object\n",
       "TRANSACTION_DATE                   datetime64[ns]\n",
       "SHIP_FROM_WAREHOUSE_CODE                   object\n",
       "SHIP_FROM_WAREHOUSE_DESCRIPTION            object\n",
       "ORDER_DATE                         datetime64[ns]\n",
       "READY_TO_PRINT_DATE                datetime64[ns]\n",
       "PRINT_TICKET_DATE                  datetime64[ns]\n",
       "VERIFIED_SHIPPED_DATE              datetime64[ns]\n",
       "BACK_ORDERED_DATE                          object\n",
       "ORDER_AGE                                    int8\n",
       "GIFT_ARTICLE_FLAG                          object\n",
       "CARRIER_NAME                               object\n",
       "CARRIER_TRACKING_NUMBER                    object\n",
       "DROPSHIP_FLAG                              object\n",
       "ORDER_STATUS                               object\n",
       "ORDER_CREATION_DATE                datetime64[ns]\n",
       "ORDER_CONFIRMATION_DATE            datetime64[ns]\n",
       "WM_ORDER_ID                                object\n",
       "WM_ORDER_LINE_ID                           object\n",
       "WM_ORDER_STATUS                            object\n",
       "WM_PICKING_START_TIME              datetime64[ns]\n",
       "WM_PICKING_END_TIME                datetime64[ns]\n",
       "WM_PICKING_AGE                            float64\n",
       "WM_PACKING_START_TIME              datetime64[ns]\n",
       "WM_PACKING_END_TIME                datetime64[ns]\n",
       "WM_PACKING_AGE                            float64\n",
       "WM_CREATED_DATE                    datetime64[ns]\n",
       "WM_UPDATED_DATE                    datetime64[ns]\n",
       "WM_SHIPPED_DATE                    datetime64[ns]\n",
       "WM_ORDER_AGE                              float64\n",
       "STORE_ID                                   object\n",
       "STORE_NAME                                 object\n",
       "SHIP_METHOD_CODE                           object\n",
       "SHIP_METHOD_NAME                           object\n",
       "SHIP_METHOD_SERVICE                        object\n",
       "SHIPMENT_SLA                              float64\n",
       "NEW_ORDER_DATE                             object\n",
       "RETURN_REASON                              object\n",
       "RETURN_FLAG                                object\n",
       "RECORD_DATE                                object\n",
       "RECORD_TIME                                object\n",
       "GROSS_SALES                                 int32\n",
       "RETURNED_STATUS                            object\n",
       "SHIPPING_DELAY                               bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e7fc9a-ae74-43f1-848e-c07264951961",
   "metadata": {},
   "source": [
    "# Filtering and Preparing the Training Dataset for Returned Status Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999fc71-b900-4bad-8d6d-a0754c6ff0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dask for handling larger datasets efficiently\n",
    "import dask.dataframe as dd\n",
    "\n",
    "#  Dask DataFrame allows for efficient handling of large datasets and delayed execution\n",
    "df_sample_dask = dd.from_pandas(df_sample, npartitions=4)  # Adjust npartitions based on data size and memory\n",
    "\n",
    "#  We use Dask to filter the records based on the 'RETURNED_STATUS' column\n",
    "df_train_dask = df_sample_dask[df_sample_dask['RETURNED_STATUS'].isin(['CANCELLED', 'RETURNED', 'DELIVERED', 'IN PROCESS'])]\n",
    "\n",
    "#  Dask performs lazy computation, so we need to explicitly call .compute() to trigger the actual computation\n",
    "df_train = df_train_dask.compute()\n",
    "\n",
    "#  Display the count of each 'RETURNED_STATUS' to verify the filtering step\n",
    "print(df_train['RETURNED_STATUS'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5fce19-5e2f-4a60-996a-1d14f1bc3da8",
   "metadata": {},
   "source": [
    "# Creating a Binary Target Variable for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382df3c0-7920-45fb-ab71-7999d3d0fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the 'RETURNED_STATUS' is 'CANCELLED' or 'RETURNED', assign 1, else assign 0\n",
    "df_train['TARGET'] = df_train['RETURNED_STATUS'].apply(lambda x: 1 if x in ['CANCELLED', 'RETURNED'] else 0)\n",
    "\n",
    "\n",
    "# This will give us an understanding of how many records are marked as 1 (CANCELLED/RETURNED) or 0 (DELIVERED/IN PROCESS)\n",
    "target_counts = df_train['TARGET'].value_counts()\n",
    "\n",
    "# Display the count of each target class\n",
    "print(target_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b382928-904e-42b6-afae-3c1f0c4200e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0dbb87-548a-4f38-be71-70e26a7d6cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SHIPPING_DELAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e6ada-a7bf-4af6-9124-4cc1bcfff0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.groupby('RETURNED_STATUS').apply(lambda x: x.sample(n=2500, replace=False))\n",
    "\n",
    "# Reset index after sampling\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04f679-a353-45da-b7ab-ef87e7fcab44",
   "metadata": {},
   "source": [
    "# Preparing Features and Target for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34000b0-f03a-4ab4-9bd1-142f27af0686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'TARGET' column has already been created where 'CANCELLED' and 'RETURNED' are assigned 1, and the rest are 0\n",
    "# Drop 'RETURNED_STATUS' and 'TARGET' from the feature set (X_train) as they are not input features for the model\n",
    "X_train = df_train.drop(columns=['RETURNED_STATUS', 'TARGET'])\n",
    "\n",
    "# The target variable (y_train) is the 'TARGET' column we created earlier\n",
    "y_train = df_train['TARGET']\n",
    "\n",
    "# Identify the numerical and categorical columns for separate preprocessing\n",
    "numerical_cols = ['SHIPMENT_SLA','UNIT_PRICE', 'WM_PICKING_AGE', 'WM_PACKING_AGE', 'WM_ORDER_AGE', 'STORE_ID',]  # Numerical features\n",
    "categorical_cols = [ 'DIVISION_CODE', 'DIVISION_NAME', 'BRAND_CODE', 'BRAND_NAME', 'CLASS_CODE', 'CLASS_NAME', 'SELLING_CHANNEL', 'CHAIN', 'WEB_ORDER_NUMBER', 'OMS_LINE_ITEM_ID', 'OMS_TICKET_ID', 'SKU_ID', 'CURRENT_STATUS', 'CURRENT_STATUS_DESCRIPTION', 'SHIP_FROM_WAREHOUSE_DESCRIPTION',  'CARRIER_NAME', 'CARRIER_TRACKING_NUMBER', 'DROPSHIP_FLAG', 'ORDER_STATUS', 'WM_ORDER_ID', 'WM_ORDER_LINE_ID', 'WM_ORDER_STATUS', 'STORE_NAME', 'SHIP_METHOD_CODE', 'SHIP_METHOD_NAME', 'SHIP_METHOD_SERVICE',  'RETURN_REASON', 'RETURN_FLAG']  # Categorical features\n",
    "\n",
    "# Display the list of numerical and categorical columns for verification\n",
    "print(\"Numerical Columns:\", numerical_cols)\n",
    "print(\"\\n\\nCategorical Columns:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a58030-eceb-41d7-8de5-adee1adeaa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[categorical_cols] = X_train[categorical_cols].fillna(X_train[categorical_cols].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36216383-6e28-40cd-a147-8a47433c74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02086ab0-924d-481e-9c27-0f64ed0f0425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count NaN values in each column\n",
    "df_sample[categorical_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8733505-3978-4788-83d0-7f918a0bd8da",
   "metadata": {},
   "source": [
    "# Preprocessing Data and Building a Machine Learning Pipeline with Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5778a6e-2002-4878-9945-65abef184a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Define a pipeline for processing numerical columns\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing numerical values with the mean\n",
    "    ('scaler', StandardScaler())  # Scale the numerical features to have zero mean and unit variance\n",
    "])\n",
    "\n",
    "#  Define a pipeline for processing categorical columns\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing categorical values with the most frequent value\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # One-hot encode categorical features, ignoring unknown categories\n",
    "])\n",
    "\n",
    "#  Combine both pipelines into a ColumnTransformer\n",
    "# The ColumnTransformer applies the numerical and categorical transformations to their respective columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_cols),  # Apply numerical pipeline to numerical columns\n",
    "        ('cat', categorical_pipeline, categorical_cols)  # Apply categorical pipeline to categorical columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "# The full pipeline consists of the preprocessing step followed by the RandomForest classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # First, apply preprocessing\n",
    "    ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))  # Then, train the RandomForest model\n",
    "])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9202715d-80a5-4bfc-9ceb-ca1ee948a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_cols:\n",
    "    mean_value = pd.to_numeric(X_train[col], errors='coerce').mean()  \n",
    "    X_train[col].fillna(mean_value, inplace=True)\n",
    "\n",
    "\n",
    "for col in categorical_cols:\n",
    "    most_frequent = X_train[col].mode(dropna=True)[0] \n",
    "    X_train[col].fillna(most_frequent, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86cff23-e333-4bff-81b0-edb588182e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7b510-dcd4-4bbd-8e35-9a54b7586948",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[categorical_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d92383-d730-465c-ad64-9b85533d8871",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train[col].mode(dropna=True), col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5d2e6-c9a2-47fd-9a90-530a7bea81f4",
   "metadata": {},
   "source": [
    "#  Hyperparameter Tuning with GridSearchCV for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0d756-a66b-4f2c-bd76-95dbbac9760b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# This grid contains possible values for several hyperparameters of the Random Forest model.\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'classifier__max_depth': [10, 20, None],  # Maximum depth of the trees\n",
    "    'classifier__min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],  # Minimum samples required at each leaf node\n",
    "    'classifier__max_features': ['sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "    'classifier__max_samples': [0.5, 1.0]  # Proportion of samples to use for fitting, to avoid overfitting\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV will randomly sample combinations of hyperparameters, and evaluate them.\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, \n",
    "                                   n_iter=10, cv=3, n_jobs=-1, verbose=2, \n",
    "                                   scoring='f1_weighted', random_state=42)\n",
    "\n",
    "# This split is necessary to evaluate model performance on unseen data (the test set).\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model on the training data using RandomizedSearchCV to find the optimal hyperparameters.\n",
    "random_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Step 11: Display the best hyperparameters found by RandomizedSearchCV\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b98d57b-6c39-49ab-b3cb-32c5f68b9a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8c3be-7268-401e-b31d-deb62854fe44",
   "metadata": {},
   "source": [
    "#  Evaluating the Best Model on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb07bc01-2a41-4d27-bc0d-ba66ee8faa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best_pipeline contains the model with the best hyperparameters found by GridSearchCV\n",
    "best_pipeline = random_search.best_estimator_\n",
    "\n",
    "#  Predict the labels (TARGET) for the test data and evaluate model performance\n",
    "y_pred_split = best_pipeline.predict(X_test_split)\n",
    "\n",
    "#  The classification report provides key metrics (precision, recall, F1-score) for both classes (CANCELLED/RETURNED and DELIVERED/IN PROCESS)\n",
    "print(\"Classification Report on CANCELLED/RETURNED records:\")\n",
    "print(classification_report(y_test_split, y_pred_split))\n",
    "\n",
    "#  Display the confusion matrix for further evaluation\n",
    "conf_matrix = confusion_matrix(y_test_split, y_pred_split)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e6c0c-6e6b-4484-b718-cc1e7af39297",
   "metadata": {},
   "source": [
    "#  Making Predictions on DELIVERED and IN PROCESS Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e5171-8d95-41e6-bdef-ed1b44807ab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We only want to predict whether DELIVERED or IN PROCESS orders will be CANCELLED or RETURNED\n",
    "df_predict = df_sample[df_sample['RETURNED_STATUS'].isin(['DELIVERED', 'IN PROCESS'])]\n",
    "\n",
    "#  Drop the 'RETURNED_STATUS' column, as it's not needed for making predictions\n",
    "X_predict = df_predict.drop(columns=['RETURNED_STATUS'])\n",
    "\n",
    "#  Use the best pipeline (with preprocessing and the trained model) to predict on the filtered dataset\n",
    "predictions = best_pipeline.predict(X_predict)\n",
    "\n",
    "#  The 'PREDICTED_CANCELLED_RETURNED' column contains the predicted labels (1 for CANCELLED/RETURNED, 0 for not)\n",
    "df_predict['PREDICTED_CANCELLED_RETURNED'] = predictions\n",
    "\n",
    "#  Display the original 'RETURNED_STATUS' along with the new 'PREDICTED_CANCELLED_RETURNED' column\n",
    "df_predict[['RETURNED_STATUS', 'PREDICTED_CANCELLED_RETURNED']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30712700-3019-4e27-a290-3f4085773609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_predict[['RETURNED_STATUS', 'PREDICTED_CANCELLED_RETURNED']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677444c5-dc09-4357-bb2f-dcc1a3be77b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Get the best model\n",
    "best_pipeline = random_search.best_estimator_\n",
    "\n",
    "# Step 12: Evaluate the best model on the test split\n",
    "y_pred_split = best_pipeline.predict(X_test_split)\n",
    "print(\"Classification Report on CANCELLED/RETURNED/DELIVERED/IN PROCESS records:\")\n",
    "print(classification_report(y_test_split, y_pred_split))\n",
    "\n",
    "# Step 13: Plot Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test_split, y_pred_split)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Step 14: Classification Report (Precision, Recall, F1-Score) as a bar plot\n",
    "report = classification_report(y_test_split, y_pred_split, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "report_df[['precision', 'recall', 'f1-score']].iloc[:-3].plot(kind='bar')\n",
    "plt.title('Precision, Recall, F1-Score by Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Step 15: ROC Curve and AUC (for binary classification tasks)\n",
    "if len(best_pipeline.classes_) == 2:  # Check if binary classification\n",
    "    # Predict probabilities for the positive class\n",
    "    y_prob = best_pipeline.predict_proba(X_test_split)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_split, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "# Step 16: Precision-Recall Curve\n",
    "precision, recall, thresholds_pr = precision_recall_curve(y_test_split, y_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f'AUC = {auc(recall, precision):.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0131f8b-1128-4556-a05b-8709bb11e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_cols:\n",
    "    mean_value = pd.to_numeric(df_train[col], errors='coerce').mean()  \n",
    "    df_train[col].fillna(mean_value, inplace=True)\n",
    "\n",
    "\n",
    "for col in categorical_cols:\n",
    "    most_frequent = df_train[col].mode(dropna=True)[0] \n",
    "    df_train[col].fillna(most_frequent, inplace=True)\n",
    "\n",
    "df_train['PREDICTED_CANCELLED_RETURNED'] =  best_pipeline.predict(df_train[numerical_cols + categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b098a711-2bc9-446d-b724-298184d0d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e146e1a-a626-46e5-94a2-127eaf84239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['RETURNED_STATUS', 'PREDICTED_CANCELLED_RETURNED']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f87ac0-a218-4259-8aec-881fa5ba88df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('PREDICTED_CANCELLED_RETURNED', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467b12f-73e7-4e2a-9052-4417942e1f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e48e0a8-577d-4017-bccc-1401278e0a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Importing the get_session function from fosforml's Snowflake session manager\n",
    "# from fosforml.model_manager.snowflakesession import get_session\n",
    "\n",
    "# # Establishing a Snowflake session for executing queries and performing operations\n",
    "# my_session = get_session()\n",
    "\n",
    "# # Define the name of the Snowflake table to query\n",
    "# table_name = 'ORDER_DATA_2412'\n",
    "\n",
    "# # Execute a SQL query to select all records from the specified table in Snowflake\n",
    "# df_sample = my_session.sql(\"select * from {}\".format(table_name)).to_pandas()\n",
    "\n",
    "# df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149949ed-b477-48fc-a748-8c43e2903e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample[categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e96653-67de-4f89-9fa9-ac6b32bba975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample.drop('PREDICTED_CANCELLED_RETURNED', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb646d-45b6-4c9c-9367-f2c987579564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea015ce-3514-469e-8432-a596abd0d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Pandas DataFrame (cust_df) into a Snowflake DataFrame\n",
    "training_datadf = my_session.createDataFrame(df_train)\n",
    "\n",
    "# Write the Snowflake DataFrame to a Snowflake table named 'casino_customers'\n",
    "# The 'overwrite' mode ensures that the table is replaced if it already exists\n",
    "training_datadf.write.mode(\"overwrite\").save_as_table(\"ORDER_DATA_2412\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9967a30e-3ada-4ba5-bba2-9180f6e71494",
   "metadata": {},
   "source": [
    "# Model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11dafb2-d598-4325-a848-779008a9ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff0d96-f72f-4ea6-b690-00c71466b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml import register_model\n",
    "\n",
    "register_model(\n",
    "  model_obj=best_pipeline,\n",
    "  session=my_session,\n",
    "  x_train=X_train_split,\n",
    "  y_train=y_train_split,\n",
    "  x_test=X_test_split,\n",
    "  y_test=y_test_split,\n",
    "  y_pred=y_pred,\n",
    "  source=\"Notebook\",\n",
    "  dataset_name=\"ORDER_DATA_2412\",\n",
    "  dataset_source=\"Snowflake\",\n",
    "  name=\"Returns_and_Cancellation\",\n",
    "  description=\"This is a Model for predicting the Returning and Cancellation orders\",\n",
    "  flavour=\"sklearn\",\n",
    "  model_type=\"classification\",\n",
    "  conda_dependencies=[\"scikit-learn==1.3.2\"],\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3eb174-5ae4-42e6-b8f5-a31470dcb654",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973506de-3876-48cc-aea8-a7bf8080e537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
